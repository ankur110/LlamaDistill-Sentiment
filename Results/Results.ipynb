{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:28:28.169939Z",
     "iopub.status.busy": "2025-11-30T12:28:28.169756Z",
     "iopub.status.idle": "2025-11-30T12:30:12.224259Z",
     "shell.execute_reply": "2025-11-30T12:30:12.223513Z",
     "shell.execute_reply.started": "2025-11-30T12:28:28.169922Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m124.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.5/465.5 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.9/753.9 kB\u001b[0m \u001b[31m822.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m350.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\n",
      "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.20.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU accelerate peft bitsandbytes transformers trl huggingface_hub scipy tensorboard datasets evaluate mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:32:06.603257Z",
     "iopub.status.busy": "2025-11-30T12:32:06.602472Z",
     "iopub.status.idle": "2025-11-30T12:32:06.607705Z",
     "shell.execute_reply": "2025-11-30T12:32:06.607014Z",
     "shell.execute_reply.started": "2025-11-30T12:32:06.603229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import PeftModel\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:32:10.840472Z",
     "iopub.status.busy": "2025-11-30T12:32:10.840177Z",
     "iopub.status.idle": "2025-11-30T12:32:10.845096Z",
     "shell.execute_reply": "2025-11-30T12:32:10.844523Z",
     "shell.execute_reply.started": "2025-11-30T12:32:10.840432Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 1. Configuration & Paths\n",
    "# ------------------------------------------------------------------\n",
    "ADAPTER_MODEL_PATH = \"/kaggle/input/mlflow-folder/mlflow_artifacts/student_model\"\n",
    "BASE_MODEL_ID = \"NousResearch/Llama-3.2-1B\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:32:25.584267Z",
     "iopub.status.busy": "2025-11-30T12:32:25.583691Z",
     "iopub.status.idle": "2025-11-30T12:32:40.028237Z",
     "shell.execute_reply": "2025-11-30T12:32:40.027205Z",
     "shell.execute_reply.started": "2025-11-30T12:32:25.584245Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8c0cd6dfbd48d8907a03763131b937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3e7abe44904f808ac76b325b740de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at NousResearch/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2048, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 2. Load Tokenizer & Model\n",
    "# ------------------------------------------------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_MODEL_PATH)\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL_ID,\n",
    "    num_labels=2,\n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=None \n",
    ")\n",
    "\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_MODEL_PATH)\n",
    "model = model.merge_and_unload()\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:32:40.029768Z",
     "iopub.status.busy": "2025-11-30T12:32:40.029453Z",
     "iopub.status.idle": "2025-11-30T12:32:47.597235Z",
     "shell.execute_reply": "2025-11-30T12:32:47.596651Z",
     "shell.execute_reply.started": "2025-11-30T12:32:40.029743Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45803fcbe3ad4b0fb728ad6c72fee358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f90a5fd24c44b08be8fda6d5575534e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63298f1419834c6aa940a2fbafedb376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75b58946cdf4d888d7dafed996e1b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a7de4f14614f689daab9134d84a7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc529e5b7e84cc8a2c935965d360b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1b0f16900f4388870993a72a851f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbaa2f15d6f545268cb916b86d376461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ef8a3b15ea46519cc239a750347598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c89cbeab6f149debbbdcf65471cfc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 3. Prepare Dataset\n",
    "# ------------------------------------------------------------------\n",
    "raw_dataset = load_dataset(\"stanfordnlp/sst2\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets = raw_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:38:17.955555Z",
     "iopub.status.busy": "2025-11-30T12:38:17.955001Z",
     "iopub.status.idle": "2025-11-30T12:38:18.737721Z",
     "shell.execute_reply": "2025-11-30T12:38:18.737090Z",
     "shell.execute_reply.started": "2025-11-30T12:38:17.955531Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: total=67349, counts={0: 29780, 1: 37569}, percentages={k: v/n for k,v in c.items()}\n",
      "validation: total=872, counts={1: 444, 0: 428}, percentages={k: v/n for k,v in c.items()}\n",
      "test: total=1821, counts={-1: 1821}, percentages={k: v/n for k,v in c.items()}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for split in (\"train\", \"validation\", \"test\"):\n",
    "    ds = tokenized_datasets[split]\n",
    "    # get label key name (could be 'labels' or 'label')\n",
    "    lab_key = \"labels\" if \"labels\" in ds.column_names else (\"label\" if \"label\" in ds.column_names else None)\n",
    "    if lab_key is None:\n",
    "        print(f\"{split}: no label column\")\n",
    "        continue\n",
    "    labels = ds[lab_key]\n",
    "    c = Counter(labels)\n",
    "    n = len(labels)\n",
    "    print(f\"{split}: total={n}, counts={dict(c)}, percentages={{k: v/n for k,v in c.items()}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:33:09.100057Z",
     "iopub.status.busy": "2025-11-30T12:33:09.099744Z",
     "iopub.status.idle": "2025-11-30T12:33:11.303227Z",
     "shell.execute_reply": "2025-11-30T12:33:11.302724Z",
     "shell.execute_reply.started": "2025-11-30T12:33:09.100034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e21e78f0aa4cf09033b04d48e857c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca9260f0fb34c62b70f67c5960498d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e8f298f9564f409ee31923a3670d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d96f6b4a544a52825d24f32915f0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 4. Metrics\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Return empty metrics if no labels exist\n",
    "    if labels is None or (isinstance(labels, np.ndarray) and len(labels) == 0):\n",
    "        return {}\n",
    "        \n",
    "    core = clf_metrics.compute(predictions=preds, references=labels)\n",
    "    try:\n",
    "        probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "        pos_probs = probs[:, 1]\n",
    "        auc = float(roc_auc_score(labels, pos_probs))\n",
    "    except:\n",
    "        auc = float(\"nan\")\n",
    "    core[\"roc_auc\"] = auc\n",
    "    return core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:34:27.169652Z",
     "iopub.status.busy": "2025-11-30T12:34:27.169123Z",
     "iopub.status.idle": "2025-11-30T12:34:27.208194Z",
     "shell.execute_reply": "2025-11-30T12:34:27.207352Z",
     "shell.execute_reply.started": "2025-11-30T12:34:27.169617Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./eval_results\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    report_to=\"none\", \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:53:37.638336Z",
     "iopub.status.busy": "2025-11-30T12:53:37.637778Z",
     "iopub.status.idle": "2025-11-30T12:53:37.654928Z",
     "shell.execute_reply": "2025-11-30T12:53:37.654149Z",
     "shell.execute_reply.started": "2025-11-30T12:53:37.638311Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.237530</td>\n",
       "      <td>0.386957</td>\n",
       "      <td>0.900229</td>\n",
       "      <td>0.903654</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.944578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.475059</td>\n",
       "      <td>0.370412</td>\n",
       "      <td>0.910550</td>\n",
       "      <td>0.913525</td>\n",
       "      <td>0.899563</td>\n",
       "      <td>0.927928</td>\n",
       "      <td>0.941697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.712589</td>\n",
       "      <td>0.352371</td>\n",
       "      <td>0.911697</td>\n",
       "      <td>0.912797</td>\n",
       "      <td>0.917995</td>\n",
       "      <td>0.907658</td>\n",
       "      <td>0.947085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000</td>\n",
       "      <td>0.950119</td>\n",
       "      <td>0.336654</td>\n",
       "      <td>0.924312</td>\n",
       "      <td>0.924658</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.912162</td>\n",
       "      <td>0.952834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step     epoch  eval_loss  eval_accuracy   eval_f1  eval_precision  \\\n",
       "0  1000  0.237530   0.386957       0.900229  0.903654        0.888889   \n",
       "1  2000  0.475059   0.370412       0.910550  0.913525        0.899563   \n",
       "2  3000  0.712589   0.352371       0.911697  0.912797        0.917995   \n",
       "3  4000  0.950119   0.336654       0.924312  0.924658        0.937500   \n",
       "\n",
       "   eval_recall  eval_roc_auc  \n",
       "0     0.918919      0.944578  \n",
       "1     0.927928      0.941697  \n",
       "2     0.907658      0.947085  \n",
       "3     0.912162      0.952834  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Training Results\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load your JSON file\n",
    "with open(\"/kaggle/input/mlflow-folder/distilled-llama-sst2/checkpoint-4210/trainer_state.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "log_history = data[\"log_history\"]\n",
    "\n",
    "# Collect only eval steps (those having eval_accuracy, eval_loss, etc.)\n",
    "rows = []\n",
    "for entry in log_history:\n",
    "    if \"eval_accuracy\" in entry:   # means this is an eval-step log\n",
    "        rows.append({\n",
    "            \"step\": entry.get(\"step\"),\n",
    "            \"epoch\": entry.get(\"epoch\"),\n",
    "            \"eval_loss\": entry.get(\"eval_loss\"),\n",
    "            \"eval_accuracy\": entry.get(\"eval_accuracy\"),\n",
    "            \"eval_f1\": entry.get(\"eval_f1\"),\n",
    "            \"eval_precision\": entry.get(\"eval_precision\"),\n",
    "            \"eval_recall\": entry.get(\"eval_recall\"),\n",
    "            \"eval_roc_auc\": entry.get(\"eval_roc_auc\"),\n",
    "        })\n",
    "\n",
    "# Convert to dataframe\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Show table\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:35:39.292856Z",
     "iopub.status.busy": "2025-11-30T12:35:39.292582Z",
     "iopub.status.idle": "2025-11-30T12:36:10.403251Z",
     "shell.execute_reply": "2025-11-30T12:36:10.402659Z",
     "shell.execute_reply.started": "2025-11-30T12:35:39.292837Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid_eval_loss: 0.3916\n",
      "Valid_eval_model_preparation_time: 0.0030\n",
      "Valid_eval_accuracy: 0.9220\n",
      "Valid_eval_f1: 0.9224\n",
      "Valid_eval_precision: 0.9352\n",
      "Valid_eval_recall: 0.9099\n",
      "Valid_eval_roc_auc: 0.9530\n",
      "Valid_eval_runtime: 31.0736\n",
      "Valid_eval_samples_per_second: 28.0620\n",
      "Valid_eval_steps_per_second: 0.9010\n"
     ]
    }
   ],
   "source": [
    "val_ds = tokenized_datasets[\"validation\"]\n",
    "\n",
    "val_ds = val_ds.rename_column(\"label\", \"labels\")\n",
    "val_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "val_metrics = trainer.evaluate(eval_dataset=val_ds)\n",
    "for key, value in val_metrics.items():\n",
    "    print(f\"Valid_{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:39:19.767099Z",
     "iopub.status.busy": "2025-11-30T12:39:19.766358Z",
     "iopub.status.idle": "2025-11-30T12:39:49.596532Z",
     "shell.execute_reply": "2025-11-30T12:39:49.595875Z",
     "shell.execute_reply.started": "2025-11-30T12:39:19.767075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- validation ---\n",
      "logits shape: (872, 2)\n",
      "logits min/max/mean per class: [-1.876 -1.97 ] [0.83  1.158] [-0.4514 -0.639 ]\n",
      "probs mean per class: [0.534  0.4656]\n",
      " label=0 count=428 logits mean for that label: [ 0.00566 -1.101  ] probs mean: [0.734 0.266]\n",
      " label=1 count=444 logits mean for that label: [-0.892  -0.1941] probs mean: [0.342  0.6577]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_logits_labels(split, batch_size=64):\n",
    "    all_logits, all_labels = [], []\n",
    "    ds = tokenized_datasets[split]\n",
    "    # Use raw tokenized inputs (they are already torch format or lists)\n",
    "    for i in range(0, len(ds), batch_size):\n",
    "        batch = ds[i:i+batch_size]\n",
    "        input_ids = torch.tensor(batch[\"input_ids\"]).to(device)\n",
    "        attention_mask = torch.tensor(batch[\"attention_mask\"]).to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = out.logits.detach().cpu().numpy()\n",
    "        all_logits.append(logits)\n",
    "        all_labels.append(np.array(batch[\"label\"]))\n",
    "    all_logits = np.concatenate(all_logits, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    return all_logits, all_labels\n",
    "\n",
    "for split in [\"validation\"]:\n",
    "    print(f\"--- {split} ---\")\n",
    "    logits, labels = get_logits_labels(split, batch_size=64)\n",
    "    print(\"logits shape:\", logits.shape)\n",
    "    print(\"logits min/max/mean per class:\", logits.min(axis=0), logits.max(axis=0), logits.mean(axis=0))\n",
    "    probs = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "    print(\"probs mean per class:\", probs.mean(axis=0))\n",
    "    if labels is not None and labels.dtype != object:\n",
    "        for lab in np.unique(labels):\n",
    "            idx = np.where(labels == lab)[0]\n",
    "            print(f\" label={lab} count={len(idx)} logits mean for that label:\", logits[idx].mean(axis=0), \"probs mean:\", probs[idx].mean(axis=0))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:44:18.073008Z",
     "iopub.status.busy": "2025-11-30T12:44:18.072712Z",
     "iopub.status.idle": "2025-11-30T12:44:47.889381Z",
     "shell.execute_reply": "2025-11-30T12:44:47.888604Z",
     "shell.execute_reply.started": "2025-11-30T12:44:18.072988Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for validation\n",
      "[[400  28]\n",
      " [ 40 404]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9091    0.9346    0.9217       428\n",
      "           1     0.9352    0.9099    0.9224       444\n",
      "\n",
      "    accuracy                         0.9220       872\n",
      "   macro avg     0.9221    0.9222    0.9220       872\n",
      "weighted avg     0.9224    0.9220    0.9220       872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def inspect_split(split, n_show=10):\n",
    "    logits, labels = get_logits_labels(split, batch_size=64)\n",
    "    probs = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    print(\"Confusion Matrix for\", split)\n",
    "    if labels is None or labels.dtype == object:\n",
    "        print(\"No labels available for this split.\")\n",
    "        return preds, labels\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    print(cm)\n",
    "    print(\"Classification report:\\n\", classification_report(labels, preds, digits=4))\n",
    "    return preds, labels\n",
    "\n",
    "_ = inspect_split(\"validation\", n_show=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8878166,
     "sourceId": 13931649,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
